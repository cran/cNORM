<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Sebastian Gary, Wolfgang Lenhard, Alexandra Lenhard" />

<meta name="date" content="2024-10-16" />

<title>Weighted Regression-Based Norming</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Weighted Regression-Based Norming</h1>
<h4 class="author">Sebastian Gary, Wolfgang Lenhard, Alexandra
Lenhard</h4>
<h4 class="date">2024-10-16</h4>



<div id="enhancing-representativeness-with-weighted-regression-based-norming-in-cnorm" class="section level2">
<h2>Enhancing Representativeness with Weighted Regression-Based Norming
in cNORM</h2>
<p>Acquiring valid norm scores fundamentally relies on the
representativeness of the norm sample. Traditionally, random sampling is
employed to meet this end, but even this approach may result in a sample
that diverges from the population structure. The <em>cNORM</em> R
package provides a potent solution by incorporating sampling weights
into the norming process, thereby diminishing the impact of
non-representative norm samples on the norm score quality. A key
component of this process is raking, or iterative proportional fitting,
which allows for the post-stratification of the norm sample based on
stratification variables (SVs), considering their population
marginals.</p>
<div id="impact-of-non-representative-norm-samples" class="section level3">
<h3>Impact of Non-Representative Norm Samples</h3>
<p>When a norm sample inadequately represents the target population,
especially regarding pertinent stratification variables, it can
compromise the quality of the resulting norm scores (Kruskal &amp;
Mosteller, 1979). An illustration of this issue is the neglect of
parental educational background when determining norm scores for a
children’s intelligence test. Such oversight can lead to skewed norm
scores, thus distorting the child’s actual intelligence level (Hernandez
et al., 2017). As norm scores commonly inform significant decisions,
like school placement or the diagnosis of learning disabilities (Gary
&amp; Lenhard, 2021; Lenhard, Lenhard &amp; Gary, 2019; Lenhard &amp;
Lenhard, 2021), any bias can potentially disadvantage those being
evaluated. Therefore, techniques such as sample weighting methods become
crucial to mitigate non-representativeness in norm samples.</p>
</div>
<div id="raking-enhancing-sample-representativeness-through-iterative-proportional-fitting" class="section level3">
<h3>Raking: Enhancing Sample Representativeness through Iterative
Proportional Fitting</h3>
<p>Raking, also called iterative proportional fitting, is a
post-stratification approach targeted to enhance sample
representativeness with respect to two or more stratification variables
. For this purpose, sample weights are computed for every case in the
norm sample based on the ratio between the proportion of the
corresponding strata in the target population and the proportion in the
actual norm sample (Lumley, 2011). The procedure can be described as an
iterative post-stratification with respect to one variable in each step.
For example, let’s assume a target population containing 49% female as
well as 51% male persons, while the resulting norm sample contains 45%
female and 55% male subjects. To enhance the representativeness of the
norm sample with respect to the SV sex (female/male), every single
female case would be weighted with <span class="math inline">\(w_{female}=\frac{49\%}{45\%}=1.09\)</span> and
every single male case with <span class="math inline">\(w_{male}=\frac{55\%}{51\%}=0.93\)</span>. For
stratifying a norm sample with respect to two or more variables, for
example sex(female/male) and education(low/medium/high), the before
described adaptation is applied several times regarding the marginals of
one variable by time iteratively. For example, if the weights are
adapted with respect to the variable sex first, the weights would be
adapted regarding education in the second step. Since the weights no
longer represent the population with respect to variable sex after the
second step, the weights are computed to SV sex in the third step
respectively to education in the fourth step and so on until the
corresponding raking weights are converged. Finally, the resulting
raking weights respectively the weighted norm sample represents the
target population with respect to the marginal proportions of the used
SVs. Each case is assigned with an according weight in a way that the
proportions of the strata in the norm sample aligns with the composition
of the representative population.</p>
</div>
<div id="integration-of-raking-weights-in-regression-based-norming-in-cnorm" class="section level3">
<h3>Integration of raking weights in regression-based norming in
cNORM</h3>
<p>The integration of raking weights in <em>cNORM</em> is accomplished
in three steps.</p>
<ul>
<li>Computation and standardization of raking weights</li>
<li>Initial ranking of test raw scores using standardized raking weights
with weighted percentile estimation</li>
<li>Regression-based norming with standardized regression weights</li>
</ul>
<div id="step-1-computation-and-standardization-of-raking-weights" class="section level4">
<h4>Step 1: Computation and standardization of raking weights</h4>
<p>Raking weights are computed regarding the proportions of the SVs in
the target population and the actual norm sample. Afterwards, the
resulting raking weights are standardized by dividing every weight by
the smallest resulting raking weight, i.e., the smallest weight is set
to 1.0, while the ratio between one weight and each other remains the
same. Consequently, underrepresented cases in the sample are weighted
with a factor larger 1.0. To compute the weights, please provide a data
frame with three columns to specify the population marginals. The first
column specifies the stratification variable, the second the factor
level of the stratification variable and the third the proportion for
the representative population. The function ‘computeWeights()’ is used
to retrieve the weights. The original data and the marginals have to be
passed as function parameters.</p>
</div>
<div id="step-2-weighted-percentile-estimation" class="section level4">
<h4>Step 2: Weighted percentile estimation</h4>
<p>Secondly, the norm sample is ranked with respect to the raking
weights using weighted percentile. This step is the actual start of the
further regression-based norming approach and it is automatically
applied in the ‘cnorm()’ function, as soon as weights are specified.</p>
</div>
<div id="step-3-regression-based-norming-with-standardized-regression-weights" class="section level4">
<h4>Step 3: Regression-based norming with standardized regression
weights</h4>
<p>Finally, the standardized raking weights are used in the weighted
best-subset regression to obtain an adequate norm model. While the
former steps can be seen as kind of data preparation, the computation of
the regression-based norm model represents the actual norming process,
since the resulting regression model is used for the actual mapping
between achieved raw score and assigned norm score. By using the
standardized raking weights in weighted regression, an overfit of the
regression model with respect to overrepresented data points should be
reduced. This third step is as well applied automatically when using the
‘cnorm()’ function.</p>
</div>
</div>
<div id="example" class="section level3">
<h3>Example</h3>
<p>In the following, the usage of raking weights in regression-based
norming with <em>cNORM</em> is illustrated in detail based the on a not
representative norm sample for the German version of the <em>Peabody
Picture Vocabulary Test</em> (PPVT-IV)</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(cNORM)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># Assign data to object norm.data</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>norm.data <span class="ot">&lt;-</span> ppvt</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="fu">head</span>(norm.data)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#&gt;      age sex migration region raw    group</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#&gt; 1 2.5971   1         0   west 120 3.160655</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#&gt; 2 2.5993   1         0   west  67 3.160655</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co">#&gt; 3 2.6241   1         0   west  23 3.160655</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co">#&gt; 4 2.8622   1         0  south  50 3.160655</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co">#&gt; 5 2.8764   1         0  south  44 3.160655</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co">#&gt; 6 2.9308   1         0   west  55 3.160655</span></span></code></pre></div>
<p>For the post-stratification, we need population marginals for the
relevant stratification variables as a data frame, with each level of
each stratification variable in a row. The data frame must contain the
names of the SVs (column 1), the single levels (column 2) and the
corresponding proportion in the target population (column 3).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Generate population marginals</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>marginals <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">var =</span> <span class="fu">c</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;sex&quot;</span>, <span class="st">&quot;migration&quot;</span>, <span class="st">&quot;migration&quot;</span>),</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>                             <span class="at">level =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>                             <span class="at">prop =</span> <span class="fu">c</span>(<span class="fl">0.51</span>, <span class="fl">0.49</span>, <span class="fl">0.65</span>, <span class="fl">0.35</span>))</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="fu">head</span>(marginals)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co">#&gt;         var level prop</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt; 1       sex     1 0.51</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">#&gt; 2       sex     2 0.49</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt; 3 migration     0 0.65</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co">#&gt; 4 migration     1 0.35</span></span></code></pre></div>
<p>To calculate raking weights, the cNORM’s ‘computeWeights()’ function
is used, with the norm sample data and the population marginals as
function parameters.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>weights <span class="ot">&lt;-</span> <span class="fu">computeWeights</span>(<span class="at">data =</span> norm.data, <span class="at">population.margins =</span> marginals)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co">#&gt; Raking converged normally after 3 iterations.</span></span></code></pre></div>
<p>Using the ‘cnorm()’ function passing the raking weights by function
parameter ‘weights’, the initial weighted ranking and the actual norming
process is started.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>norm.model <span class="ot">&lt;-</span> <span class="fu">cnorm</span>(<span class="at">raw =</span> norm.data<span class="sc">$</span>raw, <span class="at">group =</span> norm.data<span class="sc">$</span>group,</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>                    <span class="at">weights =</span> weights)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- -->
The resulting model contains four predictors with a RMSE of 3.54212.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">summary</span>(norm.model)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co">#&gt; cNORM Model Summary</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co">#&gt; -------------------</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">#&gt; Number of terms: 22 </span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#&gt; Adjusted R-squared: 0.9907 </span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt; RMSE: 3.4848 </span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt; Selection strategy: 1,  largest consistent model</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#&gt; Highest consistent model: 22 </span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">#&gt; Raw score variable: raw </span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co">#&gt; Raw score range: 7 to 221 </span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="co">#&gt; Age range: 3.160655 to 16.40039 </span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt; Regression function:</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">#&gt; raw ~ 609.659645369387 + (-84.4879873138628*L1) + (3.65960741257218*L2) + (-0.0729805623469329*L3) + (0.000688372185387521*L4) + (-2.44189464869808e-06*L5) + (-144.933081877103*A1) + (5.91188371485134*A2) + (20.5183490282374*L1A1) + (-1.10216734352554*L1A2) + (0.0149133770408513*L1A3) + (-0.860590224400587*L2A1) + (0.0507898541489258*L2A2) + (-0.000844008286956976*L2A3) + (0.016927284062236*L3A1) + (-0.00102541053420829*L3A2) + (1.77037307172903e-05*L3A3) + (-0.000154946998375205*L4A1) + (9.10218808903195e-06*L4A2) + (-1.46402546126443e-07*L4A3) + (5.20147818747766e-07*L5A1) + (-2.77042659233321e-08*L5A2) + (3.44679026709246e-10*L5A3) </span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co">#&gt; Final solution: 22 terms (highest consistent model)</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="co">#&gt; R-Square Adj. = 0.990684</span></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="co">#&gt; Final regression model: raw ~ L1 + L2 + L3 + L4 + L5 + A1 + A2 + L1A1 + L1A2 + L1A3 + L2A1 + L2A2 + L2A3 + L3A1 + L3A2 + L3A3 + L4A1 + L4A2 + L4A3 + L5A1 + L5A2 + L5A3</span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="co">#&gt; Regression function: raw ~ 609.6596454 + (-84.48798731*L1) + (3.659607413*L2) + (-0.07298056235*L3) + (0.0006883721854*L4) + (-2.441894649e-06*L5) + (-144.9330819*A1) + (5.911883715*A2) + (20.51834903*L1A1) + (-1.102167344*L1A2) + (0.01491337704*L1A3) + (-0.8605902244*L2A1) + (0.05078985415*L2A2) + (-0.000844008287*L2A3) + (0.01692728406*L3A1) + (-0.001025410534*L3A2) + (1.770373072e-05*L3A3) + (-0.0001549469984*L4A1) + (9.102188089e-06*L4A2) + (-1.464025461e-07*L4A3) + (5.201478187e-07*L5A1) + (-2.770426592e-08*L5A2) + (3.446790267e-10*L5A3)</span></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a><span class="co">#&gt; Raw Score RMSE = 3.48475</span></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a><span class="co">#&gt; Post stratification was applied. The weights range from 1 to 1.415 (m = 1.116, sd = 0.182).</span></span></code></pre></div>
<p>Moreover, the percentile plot reveals no hints on model violation,
like intersecting percentile curves. It reaches a high multiple R2 with
only few terms.</p>
<pre><code>plot(norm.model, &quot;subset&quot;)
plot(norm.model, &quot;norm&quot;)</code></pre>
</div>
<div id="caveats-and-recommendation-for-use" class="section level3">
<h3>Caveats and recommendation for use</h3>
<p>We extensively simulated biased distributions and assessed, if our
approach can mitigate the effects of unrepresentative samples. cNORM
itself already corrects for several types of sampling eror, namely if
deviations occur in specific age groups or if joint probabilities of
stratification variables are unbalanced (while preserving the
marginals). Weighted Continuous Norming as well works very well in most,
but not all use cases. Please note the following:</p>
<ul>
<li>Non-representativeness in most cases leads to (moderately) increased
error of the normed scores. It is - of course - always better to ensure
the highest feasible degree of representativeness in the data
collection.</li>
<li>The data collection should be as random as possible.</li>
<li>In most but not in all cases, Weighted Continuous Norming reduces
negative effects of non-representative norm samples. If the mean of the
standardized weights exceeds a value of <span class="math inline">\(m_{weights}=2\)</span>, this is an indication to
rather not use weighting.<br />
</li>
<li>With cNORM, representativeness need not necessarily be established
in every single age group. If the marginals are more or less correct,
weighting is unnecessary.</li>
<li>Only use stratification for variables with considerable influence on
the dependent variable.</li>
<li>If available, the probabilities of cross-classifications of the
stratification variables can be used. You can recode several variables
into one and directly specify the according population marginals
(especially in combination with the next point).</li>
<li>Avoid too many stratification variables with many fine-grained
levels. This leads to high weights in specific subgroups. Rather combine
different levels of stratification variables, if the according subgroups
do not differ in the outcome variable.</li>
</ul>
</div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ul>
<li>Gary, S., &amp; Lenhard, W., (2021). In norming we trust - Verfahren
zur statistischen Modellierung kontinuierlicher Testnormen auf dem
Prüfstand. <em>Diagnostica</em>, 67(2), 75 - 86.</li>
<li>Hernandez, A., Aguilar, C., Paradell, È., Munoz, M., Vannier, L.C.,
&amp; Vallar, F. (2017). The effect of demographic variables on the
assesment of cognitive ability. <em>Psicothema</em>. <em>29</em>(4), 469
- 474.</li>
<li>Kruskal, W., &amp; Mosteller, F. (1979). Representative sampling,
III: The current statistical literature. <em>International Statistical
Review/Revue Internationale de Statistique</em>, 245 - 265</li>
<li>Lenhard, A., Lenhard, W., Segerer, R., &amp; Suggate, S. (2015).
<em>Peabody Picture Vocabulary Test (PPVT-4)</em>. Frankfurt: Pearson
Clinical Assesment.</li>
<li>Lenhard, A., Lenhard, W., &amp; Gary, S. (2019). Continuous norming
of psychometric tests: A simulation study of parametric and
semi-parametric approaches. <em>PloS one</em>, <em>14</em>(9),
e0222279.</li>
<li>Lenhard, W., &amp; Lenhard, A. (2021). Improvement of norm score
quality via regression-based continuous norming. <em>Educational and
Psychological Measurement</em>, <em>81</em>(2), 229 - 261.</li>
<li>Lumley, T. (2011). <em>Complex surveys: A guide to analysis using
R</em> (Vol. 565); John Wiley &amp; Sons.</li>
<li>Mercer, A., Lau, A., &amp; Kennedy, C. (2018). For weighting online
opt-in samples, what matters most. <em>Pew Research Center</em>.</li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
